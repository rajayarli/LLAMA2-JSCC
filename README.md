# Modelling Large Language Models Over Joint Source Channel Codec for Semantic Communication

For 3GPP recognition of new semantic communication (SemCom) paradigms and to support ITU-T standardization, an independent, interoperable implementation is crucial. We develop and implement a novel SemCom approach by integrating advanced large language models (LLMs) into the Joint Source Channel Codec (JSCC) framework. Our proposed framework and the accompanying open implementation, significantly enhance our understanding of the practical challenges and operationalization efficiency with precision. We detailed our open implementation of Llama-2 within JSCC, available as a dynamically loadable module. Our SemCom research and implementation aim to develop a general-purpose, text-based assistant aligned with human valuesâ€”being \textit{helpful, honest, and harmless}. Our initial efforts focus on studying simple baseline techniques and evaluations, such as prompting. We provide a summary of the LLM-JSCC framework to assist others in developing interoperable versions. We propose an innovative use of context distillation for prompting that fills a gap often overlooked in existing JSCC approaches. Experiments confirm our implementation's expected SemCom behaviour, highlighting factors that influence its dynamic performance. Through extensive experimental evaluations, we observed notable improvements in the effectiveness and efficiency of SemCom compared to existing solutions, offering a scalable and efficient framework that aligns with imminent objectives and paves the way for further innovations in SemCom.






Proof of Concept; Google Colab link for Preliminary Analysis:
https://colab.research.google.com/drive/1GT-5rk0hkYlRwe8TXLblnePDPpCOKzEw#scrollTo=YMfc1pytcJ7Q 
Youtube link for code review:
https://youtu.be/nTJZis5JKrE 

